# @package _global_

# Scratch
scratch:
  num_classes: 80
  mask_dim: 256
  name: ["res2", "res3", "res4", "res5"]
  channels: [256, 512, 1024, 2048]
  height: [256, 128, 64, 32]
  width: [256, 128, 64, 32]
  # Stride and common stride determines the extra fpn levels NOTE
  stride: [4, 4, 4, 4]
  # input_shape: ${shape_spec:'res2', 3, 256, 256, 4}
  base_lr: 5.0e-6
  vision_lr: 3.0e-06

# Model
model:
  _target_: custom_models.models.sam2former.mask_former_head.MaskFormerHead
  # input_shape: ${scratch.input_shape}
  num_classes: ${scratch.num_classes}
  # Pixel Decoder
  pixel_decoder:
    _target_: custom_models.models.sam2former.msdeformattn_patch.MSDeformAttnPixelDecoder
    # input_shape: ${scratch.input_shape}
    transformer_dropout: 0.0
    transformer_nheads: 8
    transformer_dim_feedforward: 2048
    transformer_enc_layers: 6
    conv_dim: 256
    mask_dim: ${scratch.mask_dim}
    norm: "GN"
    # deformable transformer encoder args
    transformer_in_features: ["res3", "res4", "res5"]
    common_stride: 4
  loss_weight: 1.0
  ignore_value: 255
  transformer_predictor:
    _target_: custom_models.models.sam2former.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder
    in_channels: 256
    num_classes: ${scratch.num_classes}
    hidden_dim: 256
    num_queries: 100
    nheads: 8
    dim_feedforward: 2048
    dec_layers: 10
    pre_norm: false
    mask_dim: ${scratch.mask_dim}
    enforce_input_project: false
  transformer_in_feature: 'multi_scale_pixel_decoder'