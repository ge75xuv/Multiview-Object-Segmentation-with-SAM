# @package _global_

# Scratch
scratch:
  train_batch_size: 1
  num_train_workers: 10
  num_frames: 8
  max_num_objects: 3
  base_lr: 5.0e-6
  vision_lr: 3.0e-06

# Model
model:
  _target_: custom_models.models.sam2former.mask_former_head.MaskFormerHead
  # Input shape has to be {str: shape}
  input_shape: [3, 512, 512]  # put it in the scratch
  num_classes: 80  # put it in the scratch
  # Pixel Decoder
  pixel_decoder:
    _target_: custom_models.models.sam2former.msdeformattn_patch.MSDeformAttnPixelDecoder
    in_features: ["res2", "res3", "res4", "res5"]
    common_stride: 4
    input_shape: [3, 512, 512]  # put it in the scratch
    transformer_dropout: 0.0
    transformer_nheads: 8
    transformer_dim_feedforward: 2048
    transformer_enc_layers: 6
    conv_dim: 256
    mask_dim: 256  # put it in the scratch
    norm: "GN"
    # deformable transformer encoder args
    transformer_in_features: ["res3", "res4", "res5"]
  loss_weight: 1.0
  ignore_value: 255
  transformer_predictor:
    _target_: custom_models.models.sam2former.mask2former_transformer_decoder.MultiScaleMaskedTransformerDecoder
    in_channels: 256
    num_classes: 80
    hidden_dim: 256
    num_queries: 100
    nheads: 8
    dim_feedforward: 2048
    dec_layers: 10
    pre_norm: false
    mask_dim: 256
    enforce_input_proj: false
  transformer_in_feature: 'multi_scale_pixel_decoder'