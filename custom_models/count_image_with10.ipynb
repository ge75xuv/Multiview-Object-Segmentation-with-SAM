{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/guests/tuna_gurbuz/prototype\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from copy import deepcopy\n",
    "\n",
    "project_dir = os.path.dirname(os.getcwd())\n",
    "print(project_dir)\n",
    "sys.path.append(project_dir)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from omegaconf import OmegaConf\n",
    "# from sam2.build_sam import build_sam2\n",
    "from sam2.sam2_image_predictor import SAM2ImagePredictor\n",
    "import torch\n",
    "from torchvision.transforms import ToPILImage, ToTensor, Normalize\n",
    "from training.dataset.transforms import ComposeAPI, NormalizeAPI\n",
    "from tqdm import tqdm\n",
    "\n",
    "from helpers.configurations import TRACK_TO_METAINFO\n",
    "from dataset.collate_fn import collate_fn_wrapper\n",
    "from dataset.mini_dataset import MiniDataset\n",
    "from debugging.show import *\n",
    "from custom_model_builder import build_sam2_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the take 001_PKA!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5683it [00:02, 2071.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mutual IDs: 1799\n",
      "Loading the take 003_TKA!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5076it [00:02, 2035.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mutual IDs: 994\n",
      "Loading the take 005_TKA!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the take 006_PKA!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3706it [00:01, 2014.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mutual IDs: 981\n",
      "Loading the take 008_PKA!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3513it [00:01, 1912.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mutual IDs: 2679\n",
      "Loading the take 010_PKA!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the take 012_1_PKA!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1526it [00:00, 2054.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mutual IDs: 256\n",
      "Loading the take 035_PKA!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5653it [00:02, 2046.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mutual IDs: 1107\n",
      "Loading the take 037_TKA!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4237it [00:02, 2111.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lenght of the dataset! 7816\n"
     ]
    }
   ],
   "source": [
    "# Dataset\n",
    "object_labels = [16]\n",
    "len_video = 1\n",
    "multiview = True\n",
    "input_image_size = 512\n",
    "batch_size = 1\n",
    "shuffle = False\n",
    "mean = [0.3551, 0.3500, 0.3469]\n",
    "std = [0.2921, 0.2716, 0.2742]\n",
    "transforms = [ComposeAPI([NormalizeAPI(mean=mean, std=std, v2=True)])]\n",
    "revert_mean=[-.3551/.2921, -.3500/.2716, -.3469/.2742]\n",
    "revert_std=[1/.2921, 1/.2716, 1/.2742]\n",
    "revert_transform = Normalize(mean=revert_mean, std=revert_std)\n",
    "test_dataset = MiniDataset('train',\n",
    "                           num_frames=len_video,\n",
    "                           input_image_size=input_image_size,\n",
    "                           object_labels=object_labels,\n",
    "                           transforms=transforms,\n",
    "                           multiview=multiview,\n",
    "                           label_projection_type='default',\n",
    "                           collate_fn=collate_fn_wrapper,\n",
    "                           batch_size=batch_size,\n",
    "                           shuffle=shuffle,\n",
    "                           get_seg_mask=True)\n",
    "print(f'Lenght of the dataset! {len(test_dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check for the dataset\n",
    "# for jj in range(len(test_dataset)):\n",
    "#     assert test_dataset.images[jj] != []\n",
    "#     assert test_dataset.segmentation_masks[jj] != []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import re\n",
    "# for idx, im in enumerate(test_dataset.images):\n",
    "#     if re.search('camera04', str(im[0])):\n",
    "#         print(f'Found {idx}: {im[0]}')\n",
    "#         break\n",
    "# test_dataset.images[0], test_dataset.images[idx-1], test_dataset.images[idx], test_dataset.images[2*idx-1], test_dataset.images[2*idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|â–‰         | 702/7816 [01:31<15:29,  7.65it/s]\n"
     ]
    }
   ],
   "source": [
    "seed = 123  # Check seed 123 index 19966\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "# 035 idx 2761 has a problem!\n",
    "# Image\n",
    "len_objects = len(object_labels)\n",
    "toPILimage = ToPILImage()\n",
    "exist = False\n",
    "exist_idx = []\n",
    "idx = 0\n",
    "\n",
    "for idx in tqdm(range(len(test_dataset))):\n",
    "    if len(exist_idx) == 3:\n",
    "        break\n",
    "    # idx = 25424\n",
    "    # print(f'Index: {idx}')\n",
    "    frame_obj_list = test_dataset[idx]\n",
    "    if multiview:\n",
    "        image = frame_obj_list[0][0].frames[0].data\n",
    "    else:\n",
    "        image = frame_obj_list.frames[0].data\n",
    "    # print('Input Image:')\n",
    "    # toPILimage(revert_transform(image)).show()\n",
    "    if multiview:\n",
    "        for j in range(len_objects):\n",
    "            exist0 = torch.any(frame_obj_list[0][0].frames[0].objects[j].segment == True)\n",
    "            exist1 = torch.any(frame_obj_list[0][1].frames[0].objects[j].segment == True)\n",
    "            exist2 = torch.any(frame_obj_list[0][2].frames[0].objects[j].segment == True)\n",
    "            exist = exist0 or exist1 or exist2\n",
    "            if exist:\n",
    "                exist_idx.append(idx)\n",
    "                break\n",
    "    else:\n",
    "        for j in range(len_objects):\n",
    "            exist = torch.any(frame_obj_list.frames[0].objects[j].segment == True)\n",
    "            if exist:\n",
    "                exist_idx.append(idx)\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[699, 700, 701]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exist_idx\n",
    "# Obj: 0\n",
    "# 1623 - 1632\n",
    "# 2561 - 2931\n",
    "\n",
    "# Obj: 13\n",
    "# 3172 - 3216\n",
    "# 4804 - 4905\n",
    "\n",
    "# Obj: 15\n",
    "# 4442 - 4455\n",
    "# 4474 - 4484\n",
    "# 4716 - 4722\n",
    "# 4732 - 4741\n",
    "\n",
    "# Obj 13 (train)\n",
    "# 4394\n",
    "\n",
    "# Obj 13 (train) multiview\n",
    "# 1114 1115\n",
    "\n",
    "# Obj 15 (train) multiview\n",
    "# 1440, 1442, 1443\n",
    "\n",
    "# Obj 16 (train) multiview\n",
    "# 699, 700, 701"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('../temp/train_13_15.json', 'w') as f:\n",
    "    json.dump({'train_13_15': exist_idx}, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the dataset: 7816\n",
      "[PosixPath('/home/polyaxon-data/data1/MM-OR_processed/001_PKA/colorimage/camera01_colorimage-000329.jpg')] \n",
      " [PosixPath('/home/polyaxon-data/data1/MM-OR_processed/001_PKA/colorimage/camera01_colorimage-002309.jpg')] \n",
      " [PosixPath('/home/polyaxon-data/data1/MM-OR_processed/001_PKA/colorimage/camera04_colorimage-002309.jpg')]\n"
     ]
    }
   ],
   "source": [
    "len_data = len(test_dataset)\n",
    "print(f'Length of the dataset: {len_data}')\n",
    "camera_switch = (len_data//3, 2*len_data//3)\n",
    "print(test_dataset.images[0], '\\n', test_dataset.images[camera_switch[0]-1], '\\n', test_dataset.images[camera_switch[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'frames'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[37]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      9\u001b[39m cam5_vid = test_dataset[iid + \u001b[32m2\u001b[39m*len_data//\u001b[32m3\u001b[39m][\u001b[32m0\u001b[39m]\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# Use first frame\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m cam1 = \u001b[43mcam1_vid\u001b[49m\u001b[43m.\u001b[49m\u001b[43mframes\u001b[49m[\u001b[32m0\u001b[39m].data\n\u001b[32m     13\u001b[39m cam4 = cam4_vid.frames[\u001b[32m0\u001b[39m].data\n\u001b[32m     14\u001b[39m cam5 = cam5_vid.frames[\u001b[32m0\u001b[39m].data\n",
      "\u001b[31mAttributeError\u001b[39m: 'list' object has no attribute 'frames'"
     ]
    }
   ],
   "source": [
    "iid = exist_idx[-1]\n",
    "cam1 = test_dataset.images[iid]\n",
    "cam4 = test_dataset.images[iid + len_data//3]\n",
    "cam5 = test_dataset.images[iid + 2*len_data//3]\n",
    "\n",
    "# Use get item: 0) VideoDataBatch 1) Segmentation mask\n",
    "cam1_vid = test_dataset[iid][0]\n",
    "cam4_vid = test_dataset[iid + len_data//3][0]\n",
    "cam5_vid = test_dataset[iid + 2*len_data//3][0]\n",
    "\n",
    "# Use first frame\n",
    "cam1 = cam1_vid.frames[0].data\n",
    "cam4 = cam4_vid.frames[0].data\n",
    "cam5 = cam5_vid.frames[0].data\n",
    "\n",
    "gt_mask1 = cam1_vid.frames[0].objects[0].segment\n",
    "gt_mask4 = cam4_vid.frames[0].objects[0].segment\n",
    "gt_mask5 = cam5_vid.frames[0].objects[0].segment\n",
    "\n",
    "print(gt_mask1.shape)\n",
    "print(gt_mask1.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create figure and subplots\n",
    "fig, axes = plt.subplots(2, 3, figsize=(10, 6))\n",
    "\n",
    "# Transpose from tensor to numpy shape\n",
    "cam1 = revert_transform(cam1).permute(1,2,0)\n",
    "cam4 = revert_transform(cam4).permute(1,2,0)\n",
    "cam5 = revert_transform(cam5).permute(1,2,0)\n",
    "\n",
    "# First row (RGB, GT, Black Placeholder)\n",
    "axes[0,0].imshow(cam1)\n",
    "axes[0,0].set_title(\"CAM 1\")\n",
    "\n",
    "axes[0,1].imshow(cam4)\n",
    "axes[0,1].set_title(\"CAM 4\")\n",
    "\n",
    "axes[0,2].imshow(cam5)\n",
    "axes[0,2].set_title(\"CAM 5\")\n",
    "\n",
    "axes[1,0].imshow(gt_mask1, cmap='gray')\n",
    "axes[1,0].set_title(\"GT MASK 1\")\n",
    "\n",
    "axes[1,1].imshow(gt_mask4, cmap='gray')\n",
    "axes[1,1].set_title(\"GT MASK 4\")\n",
    "\n",
    "axes[1,2].imshow(gt_mask5, cmap='gray')\n",
    "axes[1,2].set_title(\"GT MASK 5\")\n",
    "\n",
    "# Remove axes for a cleaner look\n",
    "for ax in axes.ravel():\n",
    "    ax.axis('off')\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trainenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
