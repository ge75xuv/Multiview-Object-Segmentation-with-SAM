{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/guests/tuna_gurbuz/prototype\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from copy import deepcopy\n",
    "\n",
    "project_dir = os.path.dirname(os.getcwd())\n",
    "print(project_dir)\n",
    "sys.path.append(project_dir)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from omegaconf import OmegaConf\n",
    "# from sam2.build_sam import build_sam2\n",
    "from sam2.sam2_image_predictor import SAM2ImagePredictor\n",
    "import torch\n",
    "from torchvision.transforms import ToPILImage, ToTensor, Normalize\n",
    "from training.dataset.transforms import ComposeAPI, NormalizeAPI\n",
    "from tqdm import tqdm\n",
    "\n",
    "from helpers.configurations import TRACK_TO_METAINFO\n",
    "from dataset.collate_fn import collate_fn\n",
    "from dataset.mini_dataset import MiniDataset\n",
    "from debugging.show import *\n",
    "from custom_model_builder import build_sam2_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the take 001_PKA!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:02<00:00,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lenght of the dataset! 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Dataset\n",
    "object_labels = [10]\n",
    "len_video = 1\n",
    "input_image_size = 512\n",
    "batch_size = 1\n",
    "shuffle = False\n",
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]\n",
    "transforms = [ComposeAPI([NormalizeAPI(mean=mean, std=std, v2=True)])]\n",
    "revert_mean=[-.485/.229, -.456/.224, -.406/.225]\n",
    "revert_std=[1/.229, 1/.224, 1/.225]\n",
    "revert_transform = Normalize(mean=revert_mean, std=revert_std)\n",
    "test_dataset = MiniDataset('over_train',\n",
    "                           len_video=len_video,\n",
    "                           input_image_size=input_image_size,\n",
    "                           object_labels=object_labels,\n",
    "                           transforms=transforms,\n",
    "                           collate_fn=collate_fn,\n",
    "                           batch_size=batch_size,\n",
    "                           shuffle=shuffle,\n",
    "                           get_seg_mask=True)\n",
    "print(f'Lenght of the dataset! {len(test_dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 123  # Check seed 123 index 19966\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "# 035 idx 2761 has a problem!\n",
    "# Image\n",
    "len_objects = len(object_labels)\n",
    "toPILimage = ToPILImage()\n",
    "exist = False\n",
    "exist_idx = []\n",
    "idx = 0\n",
    "\n",
    "for idx in tqdm(range(len(test_dataset))):\n",
    "    if len(exist_idx) == 130:\n",
    "        break\n",
    "    # idx = 25424\n",
    "    # print(f'Index: {idx}')\n",
    "    frame_obj_list, frames_segmentation_mask = test_dataset[idx]\n",
    "    image = frame_obj_list.frames[0].data\n",
    "    # print('Input Image:')\n",
    "    # toPILimage(revert_transform(image)).show()\n",
    "    for j in range(len_objects):\n",
    "        exist = torch.any(frame_obj_list.frames[0].objects[j].segment == True)\n",
    "        # toPILimage(frame_obj_list.frames[0].objects[j].segment/255).show()\n",
    "        exist_idx.append(idx) if exist else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exist_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Point Copy-Paste from the sam2_tune\n",
    "O = len_objects\n",
    "points = torch.tensor([[i,i] for i in object_labels]).unsqueeze(1)\n",
    "labels = torch.tensor([[1]]).tile((O,1))\n",
    "print(f'Points: {points.data}')\n",
    "print(f'Labels: {labels.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Predict\n",
    "multimask_output = True\n",
    "masks, scores, logits = im_pred.predict(\n",
    "point_coords=points,\n",
    "point_labels=labels,\n",
    "multimask_output=multimask_output,\n",
    ")\n",
    "best_masks = deepcopy(masks)\n",
    "if multimask_output:\n",
    "    masks = masks[None,:,:,:] if len(masks.shape) == 3 else masks\n",
    "    scores = scores[None,:] if len(scores.shape) == 1 else scores\n",
    "    sorted_ind = np.argsort(scores, axis=1)[:,-1]\n",
    "    obj_ind = np.arange(len_objects)\n",
    "    best_masks = masks[obj_ind,sorted_ind]\n",
    "    best_scores = scores[obj_ind,sorted_ind]\n",
    "    # best_logits = logits[obj_ind,sorted_ind]\n",
    "for idx, mask in enumerate(best_masks):\n",
    "    toPILimage((mask*255).astype(np.uint8)).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trainenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
