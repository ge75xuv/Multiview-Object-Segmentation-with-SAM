{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from copy import deepcopy\n",
    "\n",
    "project_dir = os.path.dirname(os.getcwd())\n",
    "print(project_dir)\n",
    "sys.path.append(project_dir)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torchvision.transforms import ToPILImage, ToTensor, Normalize\n",
    "from training.dataset.transforms import ComposeAPI, NormalizeAPI\n",
    "from tqdm import tqdm\n",
    "\n",
    "from dataset.collate_fn import collate_fn\n",
    "from dataset.mini_dataset import MiniDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "object_labels = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 24, 25, 26, 27, 28, 29]\n",
    "len_video = 1\n",
    "input_image_size = 512\n",
    "batch_size = 1\n",
    "shuffle = False\n",
    "multiview = True\n",
    "mean = [0.3551, 0.3500, 0.3469]\n",
    "std = [0.2921, 0.2716, 0.2742]\n",
    "transforms = [ComposeAPI([NormalizeAPI(mean=mean, std=std, v2=True)])]\n",
    "revert_mean=[-.3551/.2921, -.3500/.2716, -.3469/.2742]\n",
    "revert_std=[1/.2921, 1/.2716, 1/.2742]\n",
    "revert_transform = Normalize(mean=revert_mean, std=revert_std)\n",
    "test_dataset = MiniDataset('train',\n",
    "                           num_frames=len_video,\n",
    "                           input_image_size=input_image_size,\n",
    "                           object_labels=object_labels,\n",
    "                           transforms=transforms,\n",
    "                           collate_fn=collate_fn,\n",
    "                           batch_size=batch_size,\n",
    "                           shuffle=shuffle,\n",
    "                           multiview=multiview,)\n",
    "print(f'Lenght of the dataset! {len(test_dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 3 * 1000\n",
    "test_dataset.images[idx], test_dataset.images[idx+1], test_dataset.images[idx+2], len(test_dataset.images), len(test_dataset)\n",
    "test_dataset.segmentation_masks[idx], test_dataset.segmentation_masks[idx+1], test_dataset.segmentation_masks[idx+2], len(test_dataset.segmentation_masks), len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(test_dataset.images), 3):\n",
    "    # print(f'Image {i}: {test_dataset.images[i]}')\n",
    "    # print(f'Image {i+1}: {test_dataset.images[i+1]}')\n",
    "    # print(f'Image {i+2}: {test_dataset.images[i+2]}')\n",
    "    # print('---')\n",
    "    name1 = str(test_dataset.images[i][0]).split('/')[-1].split('_')[0]\n",
    "    timestamp1 = str(test_dataset.images[i][0]).split('/')[-1].split('_')[1]\n",
    "    assert name1 == 'camera01'\n",
    "    name2 = str(test_dataset.images[i+1][0]).split('/')[-1].split('_')[0]\n",
    "    timestamp2 = str(test_dataset.images[i+1][0]).split('/')[-1].split('_')[1]\n",
    "    assert name2 == 'camera04'\n",
    "    name3 = str(test_dataset.images[i+2][0]).split('/')[-1].split('_')[0]\n",
    "    timestamp3 = str(test_dataset.images[i+2][0]).split('/')[-1].split('_')[1]\n",
    "    assert name3 == 'camera05'\n",
    "    assert timestamp1 == timestamp2 == timestamp3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiview Point Cloud Registration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam_int_ext = [(mtrx[0].numpy(), mtrx[1].numpy()) for mtrx in test_dataset.camera_features['001_PKA']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam_int = [mtrx[0] for mtrx in cam_int_ext]\n",
    "cam_ext = [mtrx[1] for mtrx in cam_int_ext]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_img(mv_idx, img_indices):\n",
    "    # Get image path\n",
    "    img_paths = test_dataset.images[img_indices, :].squeeze(1)  # get image paths for the multiview indices\n",
    "    # Load video data batch\n",
    "    video_data_batch = test_dataset[mv_idx]\n",
    "    # Inverse mean std normalization\n",
    "    img0 = revert_transform(video_data_batch[0][0].frames[0].data).numpy()\n",
    "    img1 = revert_transform(video_data_batch[0][1].frames[0].data).numpy()\n",
    "    img2 = revert_transform(video_data_batch[0][2].frames[0].data).numpy()\n",
    "    img = (img0, img1, img2)\n",
    "    # Depth path\n",
    "    depth_images = []\n",
    "    for img_path in img_paths:\n",
    "        last_part = str(img_path.parts[-1].split('/')[-1].replace('.jpg', '.tiff').replace('color', 'depth'))\n",
    "        depth_path = img_path.parents[1] / 'depthimage' / last_part\n",
    "        # Load depth image\n",
    "        gt_depth_image = Image.open(depth_path)\n",
    "        # Resize depth image to 512x512\n",
    "        gt_depth_image = gt_depth_image.resize((gt_depth_image.size[0]//2, gt_depth_image.size[1]//2))\n",
    "        depth_images.append(np.array(gt_depth_image))\n",
    "    return img, depth_images, depth_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_dataset = len(test_dataset)\n",
    "print(f'Length of the dataset: {len_dataset}')\n",
    "mv_indices = [700, 1115, 1442]\n",
    "img_views = []\n",
    "depth_views = []\n",
    "\n",
    "for mv_idx in tqdm(mv_indices):\n",
    "    # Get image path and camera index\n",
    "    img_indices = [mv_idx * 3 + kk for kk in range(3)]\n",
    "    img, gt_depth_image, depth_path = process_img(mv_idx, img_indices)\n",
    "    img = np.stack(img, axis=0)  # Stack images along a new dimension\n",
    "    gt_depth_image = np.stack(gt_depth_image, axis=0)  # Stack depth images along a new dimension\n",
    "    img_views.append(img)\n",
    "    depth_views.append(gt_depth_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_flag_dump = False\n",
    "if _flag_dump:\n",
    "    with open('../temp/mv_img_views.npy', 'wb') as f:\n",
    "        np.save(f, np.array(img_views))\n",
    "    with open('../temp/mv_depth_views.npy', 'wb') as f:\n",
    "        np.save(f, np.array(depth_views))\n",
    "    with open('../temp/camera_int.npy', 'wb') as f:\n",
    "        np.save(f, np.array(cam_int))\n",
    "    with open('../temp/camera_ext.npy', 'wb') as f:\n",
    "        np.save(f, np.array(cam_ext))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove Black Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d as o3d\n",
    "\n",
    "cam_imgs = np.array(img_views)\n",
    "depth_imgs = np.array(depth_views)\n",
    "camera_ext = np.array(cam_ext)\n",
    "camera_int = np.array(cam_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H,W = depth_imgs.shape[-2:]\n",
    "buffer = (W-H) // 2\n",
    "cam_imgs = cam_imgs[:,:,:, buffer:-buffer, :]\n",
    "assert cam_imgs.shape[-2:] == depth_imgs.shape[-2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove Padding in Intrinsics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_int[:, 1, 2] = camera_int[:, 1, 2] - buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcds = []\n",
    "num_images = cam_imgs.shape[0]\n",
    "num_images = 1\n",
    "\n",
    "for idx in range(num_images):\n",
    "  for view_idx in range(3):\n",
    "    # Get images\n",
    "    rgb = (cam_imgs[idx, view_idx].transpose(1,2,0) * 256).astype(np.uint8)\n",
    "    rgb = np.ascontiguousarray(rgb)\n",
    "    d_tmp = depth_imgs[idx, view_idx]\n",
    "    rgb = o3d.geometry.Image(rgb)\n",
    "    d = o3d.geometry.Image(d_tmp)\n",
    "    # Get extrinsics\n",
    "    extrinsics = camera_ext[view_idx]\n",
    "    # Get intrinsics\n",
    "    intrinsics = camera_int[view_idx]\n",
    "    intrinsic_o3d = o3d.camera.PinholeCameraIntrinsic(width=W, height=H, fx=intrinsics[0, 0], fy=intrinsics[1, 1], cx=intrinsics[0, 2], cy=intrinsics[1, 2])\n",
    "    # Compute RGBD\n",
    "    rgbd = o3d.geometry.RGBDImage.create_from_color_and_depth(rgb, d, convert_rgb_to_intensity=False, depth_scale=1, depth_trunc=10000000)\n",
    "    # Create PC\n",
    "    pcd = o3d.geometry.PointCloud.create_from_rgbd_image(rgbd, intrinsic_o3d)\n",
    "    pcd.points = o3d.utility.Vector3dVector(np.asarray(pcd.points) / 1000)\n",
    "    # Rotate\n",
    "    pcd.transform(extrinsics)\n",
    "    pcds.append(pcd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, pcd in enumerate(pcds):\n",
    "    o3d.io.write_point_cloud(f\"point_cloud_{i}.pcd\", pcd)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trainenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
