{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from copy import deepcopy\n",
    "\n",
    "project_dir = os.path.dirname(os.getcwd())\n",
    "print(project_dir)\n",
    "sys.path.append(project_dir)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "\n",
    "import torch\n",
    "from torchvision.transforms import ToPILImage, ToTensor, Normalize\n",
    "from training.dataset.transforms import ComposeAPI, NormalizeAPI\n",
    "from tqdm import tqdm\n",
    "\n",
    "from helpers.configurations import TRACK_TO_METAINFO\n",
    "from dataset.collate_fn import collate_fn\n",
    "from dataset.mini_dataset import MiniDataset\n",
    "from debugging.show import *\n",
    "from custom_model_builder import build_sam2_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "object_labels = [10]\n",
    "len_video = 1\n",
    "input_image_size = 512\n",
    "batch_size = 1\n",
    "shuffle = False\n",
    "mean = [0.3551, 0.3500, 0.3469]\n",
    "std = [0.2921, 0.2716, 0.2742]\n",
    "transforms = [ComposeAPI([NormalizeAPI(mean=mean, std=std, v2=True)])]\n",
    "revert_mean=[-.3551/.2921, -.3500/.2716, -.3469/.2742]\n",
    "revert_std=[1/.2921, 1/.2716, 1/.2742]\n",
    "revert_transform = Normalize(mean=revert_mean, std=revert_std)\n",
    "test_dataset = MiniDataset('over_train',\n",
    "                           num_frames=len_video,\n",
    "                           input_image_size=input_image_size,\n",
    "                           object_labels=object_labels,\n",
    "                           transforms=transforms,\n",
    "                           collate_fn=collate_fn,\n",
    "                           batch_size=batch_size,\n",
    "                           shuffle=shuffle,\n",
    "                           get_seg_mask=True)\n",
    "print(f'Lenght of the dataset! {len(test_dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 123  # Check seed 123 index 19966\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "len_objects = len(object_labels)\n",
    "toPILimage = ToPILImage()\n",
    "iid = 10000\n",
    "\n",
    "# frame_obj_list, frames_segmentation_mask = test_dataset[idx]\n",
    "# image = frame_obj_list.frames[0].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_data = len(test_dataset)\n",
    "print(f'Length of the dataset: {len_data}')\n",
    "\n",
    "# OLD SLICE\n",
    "# camera_switch = (len_data//3, 2*len_data//3)\n",
    "# print(test_dataset.images[0], '\\n', test_dataset.images[camera_switch[0]-1], '\\n', test_dataset.images[camera_switch[0]])\n",
    "\n",
    "# NEW SLICE\n",
    "print(test_dataset.images[0], '\\n',test_dataset.images[1], '\\n',test_dataset.images[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the first three images\n",
    "cam1 = test_dataset.images[iid]\n",
    "cam4 = test_dataset.images[iid + 1]\n",
    "cam5 = test_dataset.images[iid + 2]\n",
    "\n",
    "# Use get item: 0) VideoDataBatch 1) Segmentation mask\n",
    "cam1_vid = test_dataset[iid][0]\n",
    "cam4_vid = test_dataset[iid + 1][0]\n",
    "cam5_vid = test_dataset[iid + 2][0]\n",
    "\n",
    "# Use first frame\n",
    "cam1 = cam1_vid.frames[0].data\n",
    "cam4 = cam4_vid.frames[0].data\n",
    "cam5 = cam5_vid.frames[0].data\n",
    "\n",
    "gt_mask1 = cam1_vid.frames[0].objects[0].segment\n",
    "gt_mask4 = cam4_vid.frames[0].objects[0].segment\n",
    "gt_mask5 = cam5_vid.frames[0].objects[0].segment\n",
    "\n",
    "print(gt_mask1.shape)\n",
    "print(gt_mask1.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create figure and subplots\n",
    "fig, axes = plt.subplots(2, 3, figsize=(10, 6))\n",
    "\n",
    "# Transpose from tensor to numpy shape\n",
    "cam1 = revert_transform(cam1).permute(1,2,0)\n",
    "cam4 = revert_transform(cam4).permute(1,2,0)\n",
    "cam5 = revert_transform(cam5).permute(1,2,0)\n",
    "\n",
    "# First row (RGB, GT, Black Placeholder)\n",
    "axes[0,0].imshow(cam1)\n",
    "axes[0,0].set_title(\"CAM 1\")\n",
    "\n",
    "axes[0,1].imshow(cam4)\n",
    "axes[0,1].set_title(\"CAM 4\")\n",
    "\n",
    "axes[0,2].imshow(cam5)\n",
    "axes[0,2].set_title(\"CAM 5\")\n",
    "\n",
    "axes[1,0].imshow(gt_mask1, cmap='gray')\n",
    "axes[1,0].set_title(\"GT MASK 1\")\n",
    "\n",
    "axes[1,1].imshow(gt_mask4, cmap='gray')\n",
    "axes[1,1].set_title(\"GT MASK 4\")\n",
    "\n",
    "axes[1,2].imshow(gt_mask5, cmap='gray')\n",
    "axes[1,2].set_title(\"GT MASK 5\")\n",
    "\n",
    "# Remove axes for a cleaner look\n",
    "for ax in axes.ravel():\n",
    "    ax.axis('off')\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from scipy.spatial.transform import Rotation\n",
    "\n",
    "def skew(t):\n",
    "    return np.array([\n",
    "        [0, -t[2], t[1]],\n",
    "        [t[2], 0, -t[0]],\n",
    "        [-t[1], t[0], 0]\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_epipolar_lines(F, pts1):\n",
    "    # pts1: Nx2 array\n",
    "    pts1_h = np.hstack((pts1, np.ones((pts1.shape[0], 1))))  # homogeneous\n",
    "    lines2 = (F @ pts1_h.T).T  # Each row is [a, b, c]\n",
    "    return lines2\n",
    "\n",
    "def compute_epipolar_lines_with_E(E, pts1, K, K_inv):\n",
    "    # pts1: Nx2 array\n",
    "    pts1_h = np.hstack((pts1, np.ones((pts1.shape[0], 1))))  # homogeneous\n",
    "    lines2 = (E @ K_inv @ pts1_h.T)  # Image coordinates\n",
    "    lines2 = lines2.T  # Each row is [a, b, c]\n",
    "    # lines2 = (K_inv.T @ lines2).T  # Each row is [a, b, c]\n",
    "    return lines2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_epilines(img2, lines, K=None, color=(255, 0, 0)):\n",
    "    if K is None:\n",
    "        h, w = img2.shape[:2]\n",
    "        for r in lines:\n",
    "            # a, b, c = r\n",
    "            # x0, x1 = 0, w\n",
    "            # y0 = int((-c - a * x0) / b)\n",
    "            # y1 = int((-c - a * x1) / b)\n",
    "            x0,y0 = map(int, [0, -r[2]/r[1] ])\n",
    "            x1,y1 = map(int, [w, -(r[2]+r[0]*w)/r[1] ])\n",
    "            img2 = cv2.line(img2, (x0, y0), (x1, y1), color, 2)\n",
    "    else:\n",
    "        for r in lines:\n",
    "            x0,y0 = map(int, [-K[0,2], -r[2]/r[1] ])\n",
    "            x1,y1 = map(int, [K[0,2], -(r[2]+r[0]*K[0,2])/r[1] ])\n",
    "            img_coords = np.ones((2, 3))\n",
    "            img_coords[0, :] = x0, y0, 1\n",
    "            img_coords[1, :] = x1, y1, 1\n",
    "            img_coords = K @ img_coords.T\n",
    "            print(img_coords)\n",
    "            x0, y0 = int(img_coords[0, 0]), int(img_coords[1, 0])\n",
    "            x1, y1 = int(img_coords[0, 1]), int(img_coords[1, 1])\n",
    "            img2 = cv2.line(img2, (x0, y0), (x1, y1), color, 2)\n",
    "    return img2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_camera_data(camera_data):\n",
    "    intrinsics_json = camera_data['value0']['color_parameters']['intrinsics_matrix']\n",
    "    K = np.asarray([[intrinsics_json['m00'], intrinsics_json['m10'], intrinsics_json['m20']],\n",
    "                    [intrinsics_json['m01'], intrinsics_json['m11'], intrinsics_json['m21']],\n",
    "                    [0, 0, 1]])\n",
    "\n",
    "    extrinsics_json = camera_data['value0']['camera_pose']\n",
    "    trans = extrinsics_json['translation']\n",
    "    rot = extrinsics_json['rotation']\n",
    "    extrinsics = np.zeros((4, 4), dtype=np.float32)\n",
    "    R = Rotation.from_quat([rot['x'], rot['y'], rot['z'], rot['w']]).as_matrix()\n",
    "    extrinsics[:3, :3] = R\n",
    "    t = [trans['m00'], trans['m10'], trans['m20'], 1]\n",
    "    extrinsics[:, 3] = t\n",
    "\n",
    "    return K, extrinsics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "take_path = '/home/polyaxon-data/data1/MM-OR_processed/001_PKA/'\n",
    "camera_files = ['camera01.json', 'camera04.json', 'camera05.json']\n",
    "camera_int_ext = []\n",
    "for json_file in camera_files:\n",
    "    with open(os.path.join(take_path, json_file), 'r') as f:\n",
    "        camera_data = json.load(f)\n",
    "    intr, ext = load_camera_data(camera_data)\n",
    "    camera_int_ext.append((intr, ext))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K0, ext0 = camera_int_ext[0]\n",
    "K1, ext1 = camera_int_ext[1]\n",
    "\n",
    "R0, t0 = ext0[:3, :3], ext0[:3, 3]\n",
    "R1, t1 = ext1[:3, :3], ext1[:3, 3]\n",
    "\n",
    "# Main computation\n",
    "ext = ext1 @ np.linalg.inv(ext0)\n",
    "R, t = ext[:3, :3], ext[:3, 3]\n",
    "# print('R:', R)\n",
    "# print('t:', t)\n",
    "\n",
    "# Sanity Check (works fine)\n",
    "# R = R1 @ R0.T\n",
    "# t = t1 - R @ t0\n",
    "# print('R:', R)\n",
    "# print('t:', t)\n",
    "\n",
    "# Check Calibration Matrices\n",
    "# print('K0:', K0)\n",
    "# print('K1:', K1)\n",
    "K = K0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pts1 = np.array([[100, 100], [200, 200], [300, 300], [400, 400], [500, 500]])\n",
    "E = skew(t) @ R\n",
    "inv_K = np.linalg.inv(K)\n",
    "F = inv_K.T @ E @ inv_K\n",
    "lines2 = compute_epipolar_lines(F, pts1)\n",
    "lines2_E = compute_epipolar_lines_with_E(E, pts1, K, inv_K)\n",
    "# lines2 = cv2.computeCorrespondEpilines(pts1.reshape(-1, 1, 2), 1, F).squeeze(1)\n",
    "# lines2 = lines2_self\n",
    "img2_with_lines = draw_epilines(cam4.numpy().copy(), lines2_E, K=K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lines2)\n",
    "print(lines2_E)\n",
    "# print(lines2_self)\n",
    "# img2 = cam4.numpy().copy()\n",
    "# img2_with_lines = cv2.line(img2, (0, 0), (512, 512), (255, 0, 0), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the image with feature points\n",
    "img1_with_points = cam1.numpy().copy()\n",
    "plt.imshow(img1_with_points)\n",
    "plt.scatter(pts1[:, 0], pts1[:, 1], c='r', s=10)\n",
    "plt.title(\"Feature Points\")\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# Display the image with epipolar lines\n",
    "plt.imshow(img2_with_lines)\n",
    "plt.title(\"Epipolar Lines\")\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# cv2.imshow('Epipolar Lines', img2_with_lines)\n",
    "# cv2.waitKey(10)\n",
    "# cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trainenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
