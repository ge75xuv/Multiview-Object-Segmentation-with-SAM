{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToPILImage\n",
    "from tqdm import tqdm\n",
    "from training.dataset.transforms import ComposeAPI, NormalizeAPI\n",
    "\n",
    "project_dir = os.path.dirname(os.path.dirname(os.getcwd()))\n",
    "print(project_dir)\n",
    "sys.path.append(project_dir)\n",
    "\n",
    "from mini_dataset import MiniDataset\n",
    "from collate_fn import collate_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_frames = 1\n",
    "input_image_size = 512\n",
    "transforms = [ComposeAPI([NormalizeAPI(mean=[0.0, 0.0, 0.0], std=[1.0, 1.0, 1.0], v2=True)])]\n",
    "object_labels = [10]\n",
    "batch_size = 1\n",
    "shuffle = True\n",
    "collate_fn = collate_fn\n",
    "train_dataset = MiniDataset('train',\n",
    "                             num_frames=num_frames,\n",
    "                             input_image_size=input_image_size,\n",
    "                             object_labels=object_labels,\n",
    "                             transforms=transforms,\n",
    "                             collate_fn=collate_fn,\n",
    "                             batch_size=batch_size,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_dataset = len(train_dataset)\n",
    "print(f\"Dataset length: {len_dataset}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_samples = 0\n",
    "mean = 0.0\n",
    "std = 0.0\n",
    "batch_size = 100\n",
    "im_list = []\n",
    "\n",
    "for idx, im_path in tqdm(enumerate(train_dataset.images)):\n",
    "    img = np.array(Image.open(im_path[0]).convert(\"RGB\"))\n",
    "    img = torch.from_numpy(img).permute(2, 0, 1).float() / 255.0\n",
    "    im_list.append(img)\n",
    "    if len(im_list) == batch_size:\n",
    "        try:\n",
    "            img = torch.stack(im_list, dim=0).to('cuda')\n",
    "        except RuntimeError as e:\n",
    "            print(f\"Error processing batch {idx}: {e}\")\n",
    "            for im in im_list:\n",
    "                img = im.to('cuda')\n",
    "                im_vec = img.flatten(-2)\n",
    "                mean += im_vec.mean(-1)\n",
    "                std += im_vec.std(-1)\n",
    "                nb_samples += 1\n",
    "            im_list = []\n",
    "            continue\n",
    "        im_list = []\n",
    "        im_vec = img.flatten(-2)\n",
    "        mean += im_vec.mean(-1).sum(0)\n",
    "        std += im_vec.std(-1).sum(0)\n",
    "        nb_samples += batch_size\n",
    "    elif idx == len_dataset - 1:\n",
    "        try:\n",
    "            img = torch.stack(im_list, dim=0).to('cuda')\n",
    "        except RuntimeError as e:\n",
    "            print(f\"Error processing batch {idx}: {e}\")\n",
    "            for im in im_list:\n",
    "                img = im.to('cuda')\n",
    "                im_vec = img.flatten(-2)\n",
    "                mean += im_vec.mean(-1)\n",
    "                std += im_vec.std(-1)\n",
    "                nb_samples += 1\n",
    "            im_list = []\n",
    "            continue\n",
    "        im_list = []\n",
    "        im_vec = img.flatten(-2)\n",
    "        mean += im_vec.mean(-1).sum(0)\n",
    "        std += im_vec.std(-1).sum(0)\n",
    "        nb_samples += len(im_vec)\n",
    "\n",
    "mean /= nb_samples\n",
    "std /= nb_samples\n",
    "\n",
    "print(f'Sample size: {nb_samples}')\n",
    "print(f'Mean: {mean}')\n",
    "print(f'Std: {std}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train (subsampled)\n",
    "# 10001\n",
    "# tensor([0.3578, 0.3607, 0.3501])\n",
    "# tensor([0.2861, 0.2749, 0.2712])\n",
    "\n",
    "## Overtrain 001-PKA\n",
    "# Sample size: 102\n",
    "# Mean: tensor([0.3551, 0.3500, 0.3469])\n",
    "# Std: tensor([0.2921, 0.2716, 0.2742])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trainenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
