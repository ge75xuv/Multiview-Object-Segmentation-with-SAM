{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "project_dir = os.path.dirname(os.getcwd())\n",
    "print(project_dir)\n",
    "sys.path.append(project_dir)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "import torch\n",
    "from torchvision.transforms import ToPILImage, ToTensor, Normalize\n",
    "from training.dataset.transforms import ComposeAPI, NormalizeAPI\n",
    "from tqdm import tqdm\n",
    "\n",
    "from helpers.configurations import TRACK_TO_METAINFO\n",
    "from dataset.collate_fn import collate_fn\n",
    "from dataset.mini_dataset import MiniDataset\n",
    "from debugging.show import *\n",
    "from custom_model_builder import build_sam2_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "object_labels = [18]\n",
    "len_video = 1\n",
    "input_image_size = 512\n",
    "batch_size = 1\n",
    "shuffle = False\n",
    "mean = [0.3551, 0.3500, 0.3469]\n",
    "std = [0.2921, 0.2716, 0.2742]\n",
    "transforms = [ComposeAPI([NormalizeAPI(mean=mean, std=std, v2=True)])]\n",
    "revert_mean=[-.3551/.2921, -.3500/.2716, -.3469/.2742]\n",
    "revert_std=[1/.2921, 1/.2716, 1/.2742]\n",
    "revert_transform = Normalize(mean=revert_mean, std=revert_std)\n",
    "test_dataset = MiniDataset('val',\n",
    "                           num_frames=len_video,\n",
    "                           input_image_size=input_image_size,\n",
    "                           object_labels=object_labels,\n",
    "                           transforms=transforms,\n",
    "                           collate_fn=collate_fn,\n",
    "                           batch_size=batch_size,\n",
    "                           shuffle=shuffle,\n",
    "                           get_seg_mask=True)\n",
    "print(f'Lenght of the dataset! {len(test_dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 123  # Check seed 123 index 19966\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "len_objects = len(object_labels)\n",
    "toPILimage = ToPILImage()\n",
    "# iid = 3333  # Check seed 123 index 19966\n",
    "iid = 3333"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f'Length of the dataset: {len(test_dataset)}')\n",
    "\n",
    "# # NEW SLICE\n",
    "# print(test_dataset.images[0], '\\n',test_dataset.images[1], '\\n',test_dataset.images[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the first three images\n",
    "cam1 = test_dataset.images[iid]\n",
    "cam4 = test_dataset.images[iid + 1]\n",
    "cam5 = test_dataset.images[iid + 2]\n",
    "\n",
    "print(f'Cam1: {cam1}, Cam4: {cam4}, Cam5: {cam5}')\n",
    "\n",
    "# Use get item: 0) VideoDataBatch 1) Segmentation mask\n",
    "cam1_vid = test_dataset[iid]\n",
    "cam4_vid = test_dataset[iid + 1]\n",
    "cam5_vid = test_dataset[iid + 2]\n",
    "\n",
    "# Use first frame\n",
    "cam1 = cam1_vid.frames[0].data\n",
    "cam4 = cam4_vid.frames[0].data\n",
    "cam5 = cam5_vid.frames[0].data\n",
    "\n",
    "gt_mask1 = cam1_vid.frames[0].objects[0].segment\n",
    "gt_mask4 = cam4_vid.frames[0].objects[0].segment\n",
    "gt_mask5 = cam5_vid.frames[0].objects[0].segment\n",
    "\n",
    "print(gt_mask1.shape)\n",
    "print(gt_mask1.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create figure and subplots\n",
    "fig, axes = plt.subplots(2, 3, figsize=(10, 6))\n",
    "\n",
    "# Transpose from tensor to numpy shape\n",
    "cam1 = revert_transform(cam1).permute(1,2,0)\n",
    "cam4 = revert_transform(cam4).permute(1,2,0)\n",
    "cam5 = revert_transform(cam5).permute(1,2,0)\n",
    "\n",
    "# First row (RGB, GT, Black Placeholder)\n",
    "axes[0,0].imshow(cam1)\n",
    "axes[0,0].set_title(\"CAM 1\")\n",
    "\n",
    "axes[0,1].imshow(cam4)\n",
    "axes[0,1].set_title(\"CAM 4\")\n",
    "\n",
    "axes[0,2].imshow(cam5)\n",
    "axes[0,2].set_title(\"CAM 5\")\n",
    "\n",
    "axes[1,0].imshow(gt_mask1, cmap='gray')\n",
    "axes[1,0].set_title(\"GT MASK 1\")\n",
    "\n",
    "axes[1,1].imshow(gt_mask4, cmap='gray')\n",
    "axes[1,1].set_title(\"GT MASK 4\")\n",
    "\n",
    "axes[1,2].imshow(gt_mask5, cmap='gray')\n",
    "axes[1,2].set_title(\"GT MASK 5\")\n",
    "\n",
    "# Remove axes for a cleaner look\n",
    "for ax in axes.ravel():\n",
    "    ax.axis('off')\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# is_black_row = (cam1[:,:,0] <= 0)  # Check along width and channels\n",
    "# pos_padding = np.where(is_black_row == False)\n",
    "# start = pos_padding[0][0]\n",
    "# end = pos_padding[0][-1]\n",
    "\n",
    "# # Slice the predictions and ground truth masks\n",
    "# if start == 64:\n",
    "#     cam1 = cam1[start:end+1, :, :]\n",
    "#     cam4 = cam4[start:end+1, :, :]\n",
    "#     cam5 = cam5[start:end+1, :, :]\n",
    "# elif start == 0:\n",
    "#     pass\n",
    "# else:\n",
    "#     raise ValueError(\"Padding not found in the image\")\n",
    "start = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from scipy.spatial.transform import Rotation\n",
    "\n",
    "def skew(t):\n",
    "    return np.array([\n",
    "        [0, -t[2], t[1]],\n",
    "        [t[2], 0, -t[0]],\n",
    "        [-t[1], t[0], 0]\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_epipolar_lines(ext, K_line, K_pt, pts1):\n",
    "    # pts1: Nx2 array\n",
    "    R, t = ext[:3, :3], ext[:3, 3]\n",
    "    E = skew(t) @ R\n",
    "    inv_K1 = np.linalg.inv(K_line)\n",
    "    inv_K0 = np.linalg.inv(K_pt)\n",
    "    F = inv_K0.T @ E @ inv_K1\n",
    "    pts1_h = np.hstack((pts1, np.ones((pts1.shape[0], 1))))  # homogeneous\n",
    "    lines2 = (F @ pts1_h.T).T  # Each row is [a, b, c]\n",
    "    return lines2\n",
    "\n",
    "def draw_epilines(img2, lines, colors, padding=0):\n",
    "    h, w = img2.shape[:2]\n",
    "    for r, color in zip(lines, colors):\n",
    "        color = color.tolist() if isinstance(color, np.ndarray) else color\n",
    "        # a, b, c = r\n",
    "        # x0, x1 = 0, w\n",
    "        # y0 = int((-c - a * x0) / b)\n",
    "        # y1 = int((-c - a * x1) / b)\n",
    "        x0,y0 = map(int, [0, -(r[2])/r[1] - padding])\n",
    "        x1,y1 = map(int, [w, -(r[2] + r[0]*w)/r[1] - padding])\n",
    "        img2 = cv2.line(img2, (x0, y0), (x1, y1), color, 2)\n",
    "    return img2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_camera_data(camera_data, downscale=1):\n",
    "    h, w = camera_data['value0']['color_parameters']['height'], camera_data['value0']['color_parameters']['width']\n",
    "    h_, w_ = h // downscale, w // downscale\n",
    "    padding = (w_ - h_) // 2\n",
    "    # padding = 0\n",
    "    intrinsics_json = camera_data['value0']['color_parameters']['intrinsics_matrix']\n",
    "    K = np.asarray([[intrinsics_json['m00'] / downscale, intrinsics_json['m10'], intrinsics_json['m20'] / downscale],\n",
    "                    [intrinsics_json['m01'], intrinsics_json['m11'] / downscale, intrinsics_json['m21'] / downscale + padding],\n",
    "                    [0, 0, 1]])\n",
    "    # Extrinsics Depth\n",
    "    extrinsics_json = camera_data['value0']['camera_pose']\n",
    "    trans = extrinsics_json['translation']\n",
    "    rot = extrinsics_json['rotation']\n",
    "    extrinsics = np.zeros((4, 4), dtype=np.float32)\n",
    "    R = Rotation.from_quat([rot['x'], rot['y'], rot['z'], rot['w']]).as_matrix()\n",
    "    extrinsics[:3, :3] = R\n",
    "    t = [trans['m00'], trans['m10'], trans['m20'], 1]\n",
    "    extrinsics[:, 3] = t\n",
    "\n",
    "    # Extrinsics Color\n",
    "    color2depth_json = camera_data['value0']['color2depth_transform']\n",
    "    trans = color2depth_json['translation']\n",
    "    rot = color2depth_json['rotation']\n",
    "    color2depth_transform = np.zeros((4, 4), dtype=np.float32)\n",
    "    rot_matrix = Rotation.from_quat([rot['x'], rot['y'], rot['z'], rot['w']]).as_matrix()\n",
    "    color2depth_transform[:3, :3] = rot_matrix\n",
    "    color2depth_transform[:, 3] = [trans['m00'], trans['m10'], trans['m20'], 1]\n",
    "    depth_extrinsics = np.copy(extrinsics)\n",
    "    extrinsics = extrinsics @ color2depth_transform  # Extrinsics were given for the depth camera, convert them to color camera\n",
    "    extrinsics = extrinsics @ np.array([[1, 0, 0, 0], [0, -1, 0, 0], [0, 0, -1, 0], [0, 0, 0, 1]], dtype=np.float32)\n",
    "\n",
    "    # Distortion\n",
    "    rad_dist = camera_data['value0']['color_parameters']['radial_distortion']\n",
    "    tan_dist = camera_data['value0']['color_parameters']['tangential_distortion']\n",
    "    dist = [rad_dist.pop('m00'), rad_dist.pop('m10'), tan_dist.pop('m00'), tan_dist.pop('m10')]\n",
    "    dist += [rd for rd in rad_dist.values()]\n",
    "    dist = np.array(dist, dtype=np.float32)\n",
    "\n",
    "    return K, extrinsics, padding, dist, depth_extrinsics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = test_dataset.images[iid][0]  # Get the file name from the dataset, list to string\n",
    "print(f'File name: {file_name}')\n",
    "take_path = file_name.parent.parent\n",
    "# take_path = '/home/polyaxon-data/data1/MM-OR_processed/001_PKA/'\n",
    "downscale = 4\n",
    "camera_files = ['camera01.json', 'camera04.json', 'camera05.json']\n",
    "camera_int_ext = []\n",
    "for json_file in camera_files:\n",
    "    with open(os.path.join(take_path, json_file), 'r') as f:\n",
    "        camera_data = json.load(f)\n",
    "    intr, ext, padding, dist, depth_ext = load_camera_data(camera_data, downscale)\n",
    "    camera_int_ext.append((intr, ext, dist, depth_ext))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# json_data = {i: [cam[0].tolist(), cam[1].tolist()] for i, cam in enumerate(camera_int_ext)}\n",
    "# with open('../camera_int_ext.json', 'w') as f:\n",
    "#     json.dump(json_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K0, ext0, dist0, depth_ext0 = camera_int_ext[0]\n",
    "K1, ext1, dist1, depth_ext1 = camera_int_ext[1]\n",
    "K2, ext2, dist2, depth_ext2 = camera_int_ext[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_inverse(ext):\n",
    "    inv = np.zeros((4, 4), dtype=np.float32)\n",
    "    inv[:3, :3] = ext[:3,:3].T\n",
    "    inv[:3, 3] = -ext[:3,:3].T @ ext[:3, 3]\n",
    "    return inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute relative transforms\n",
    "inv0 = compute_inverse(ext0)\n",
    "inv1 = compute_inverse(ext1)\n",
    "inv2 = compute_inverse(ext2)\n",
    "\n",
    "ext_1_to_0 = inv0 @ ext1\n",
    "ext_2_to_0 = inv0 @ ext2\n",
    "\n",
    "ext_0_to_1 = inv1 @ ext0\n",
    "ext_2_to_1 = inv1 @ ext2\n",
    "\n",
    "ext_0_to_2 = inv2 @ ext0\n",
    "ext_1_to_2 = inv2 @ ext1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_points_idx = -1\n",
    "# Define points in image 4\n",
    "y, x = torch.where(gt_mask1 == 255)\n",
    "y -= start  # We remove the padding should lift the mask\n",
    "pts_cam1 = torch.cat([x.unsqueeze(1), y.unsqueeze(1)], dim=1).numpy()[0:num_points_idx]\n",
    "\n",
    "# Define points in image 4\n",
    "y, x = torch.where(gt_mask4 == 255)\n",
    "y -= start  # We remove the padding should lift the mask\n",
    "pts_cam4 = torch.cat([x.unsqueeze(1), y.unsqueeze(1)], dim=1).numpy()[0:num_points_idx]\n",
    "\n",
    "# Define Points in Image 5\n",
    "y, x = torch.where(gt_mask5 == 255)\n",
    "y -= start  # We remove the padding should lift the mask\n",
    "pts_cam5 = torch.cat([x.unsqueeze(1), y.unsqueeze(1)], dim=1).numpy()[0:num_points_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute epipolar lines\n",
    "epi_lines_4_to_1 = compute_epipolar_lines(ext_1_to_0, K0, K1, pts_cam4)\n",
    "epi_lines_5_to_1 = compute_epipolar_lines(ext_2_to_0, K0, K2, pts_cam5)\n",
    "\n",
    "epi_lines_1_to_4 = compute_epipolar_lines(ext_0_to_1, K1, K0, pts_cam1)\n",
    "epi_lines_5_to_4 = compute_epipolar_lines(ext_2_to_1, K1, K2, pts_cam5)\n",
    "\n",
    "epi_lines_1_to_5 = compute_epipolar_lines(ext_0_to_2, K2, K0, pts_cam1)\n",
    "epi_lines_4_to_5 = compute_epipolar_lines(ext_1_to_2, K2, K1, pts_cam4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Project Cam 4 Points on Cam 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define colors for points\n",
    "num_points = pts_cam4.shape[0]\n",
    "colors4 = plt.cm.jet(np.linspace(0, 1, num_points))[:, :] * 255  # RGB 0-255\n",
    "colors4 = colors4.astype(np.uint8)\n",
    "cam1_draw = cam1.numpy().copy()\n",
    "\n",
    "# Draw Epipolar Lines\n",
    "cam1_draw = draw_epilines(cam1_draw, epi_lines_4_to_1, colors4, padding=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Project Cam 5 Points on Cam 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define colors for points\n",
    "num_points = pts_cam5.shape[0]\n",
    "colors5 = plt.cm.jet(np.linspace(0, 1, num_points))[:, :] * 255  # RGB 0-255\n",
    "colors5 = colors5.astype(np.uint8)\n",
    "\n",
    "# Draw Epipolar Lines\n",
    "cam1_draw = draw_epilines(cam1_draw, epi_lines_5_to_1, colors5, padding=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img4_color = cam4.numpy().copy()\n",
    "for pt, color in zip(pts_cam4, colors4):\n",
    "    pt_int = tuple(np.round(pt).astype(int))\n",
    "    img4_color = cv2.circle(img4_color, pt_int, 4, color.tolist(), -1)\n",
    "\n",
    "img5_color = cam5.numpy().copy()\n",
    "for pt, color in zip(pts_cam5, colors5):\n",
    "    pt_int = tuple(np.round(pt).astype(int))\n",
    "    img5_color = cv2.circle(img5_color, pt_int, 4, color.tolist(), -1)\n",
    "    \n",
    "figsize = np.array([8,6])\n",
    "fig, axs = plt.subplots(2, 3, figsize=figsize, )\n",
    "\n",
    "axs[0,0].imshow(cam1.numpy().copy())\n",
    "axs[0,0].axis('off')\n",
    "axs[0,0].set_title(\"Im 1\")\n",
    "\n",
    "axs[0,1].imshow(cam4.numpy().copy())\n",
    "axs[0,1].axis('off')\n",
    "axs[0,1].set_title(\"Im 4\")\n",
    "\n",
    "axs[0,2].imshow(cam5.numpy().copy())\n",
    "axs[0,2].axis('off')\n",
    "axs[0,2].set_title(\"Im 5\")\n",
    "\n",
    "axs[1,0].imshow(cam1_draw)\n",
    "axs[1,0].axis('off')\n",
    "axs[1,0].set_title(\"Epilines\")\n",
    "\n",
    "axs[1,1].imshow(img4_color)\n",
    "axs[1,1].axis('off')\n",
    "axs[1,1].set_title(\"Points 4\")\n",
    "\n",
    "axs[1,2].imshow(img5_color)\n",
    "axs[1,2].axis('off')\n",
    "axs[1,2].set_title(\"Points 5\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skip = 1  # Skip every 10th point for visualization\n",
    "a, b, c = epi_lines_4_to_1.T[:, ::skip]\n",
    "a, b, c = a[:, None], b[:, None], c[:, None]\n",
    "k, l, m = epi_lines_5_to_1.T[:, ::skip]\n",
    "k, l, m = k[:, None], l[:, None], m[:, None]\n",
    "\n",
    "def intersection(a, b, c, k, l, m):\n",
    "    x = (-c * l + m * b) / (a * l - k * b)\n",
    "    y = (-c - a * x) / b\n",
    "    return np.concatenate((x, y), axis=1)\n",
    "\n",
    "# Calculate the intersection point\n",
    "for i in range(len(a)):\n",
    "    if i == 0:\n",
    "        intersect_point = intersection(a[0:1], b[0:1], c[0:1], k, l, m)\n",
    "    else:\n",
    "        curr_point = intersection(a[i:i+1], b[i:i+1], c[i:i+1], k, l, m)\n",
    "        intersect_point = np.concatenate((intersect_point, curr_point), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1_color = cam1.numpy().copy()\n",
    "for pt in intersect_point:\n",
    "    pt_int = tuple(np.round(pt).astype(int))\n",
    "    img1_color = cv2.circle(img1_color, pt_int, 2, [255, 0, 0], 1)\n",
    "\n",
    "plt.imshow(img1_color)\n",
    "plt.axis('off')\n",
    "plt.title(\"Intersection Points\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trainenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
