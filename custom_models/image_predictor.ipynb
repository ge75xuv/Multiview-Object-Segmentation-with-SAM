{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from copy import deepcopy\n",
    "\n",
    "project_dir = os.path.dirname(os.getcwd())\n",
    "print(project_dir)\n",
    "sys.path.append(project_dir)\n",
    "\n",
    "from hydra import initialize\n",
    "try:\n",
    "    initialize(version_base=None, config_path=\"../sam2_logs/\", job_name=\"predict_run\")\n",
    "except ValueError:\n",
    "    pass\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from omegaconf import OmegaConf\n",
    "# from sam2.build_sam import build_sam2\n",
    "from sam2.sam2_image_predictor import SAM2ImagePredictor\n",
    "import torch\n",
    "from torchvision.transforms import ToPILImage, ToTensor, Normalize\n",
    "from training.dataset.transforms import ComposeAPI, NormalizeAPI\n",
    "\n",
    "from helpers.configurations import TRACK_TO_METAINFO\n",
    "from dataset.collate_fn import collate_fn\n",
    "from dataset.mini_dataset import MiniDataset\n",
    "from debugging.show import *\n",
    "from custom_model_builder import build_sam2_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_size_dict = {\n",
    "    'base': {\n",
    "        'config': '03_12_22_12/config_resolved.yaml',\n",
    "        'ck': '/home/guests/tuna_gurbuz/prototype/sam2_logs/03_12_22_12/checkpoints/checkpoint_40.pt',\n",
    "        },\n",
    "}\n",
    "\n",
    "# Model\n",
    "model_size = 'base'\n",
    "config = model_size_dict[model_size]['config']\n",
    "ck = model_size_dict[model_size]['ck']\n",
    "# submodel = build_sam2(config, ck, 'cpu')\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "submodel, object_labels = build_sam2_predict(config, ck, device=device)\n",
    "im_pred = SAM2ImagePredictor(submodel)\n",
    "im_pred._bb_feat_sizes = [\n",
    "        (128, 128),\n",
    "        (64, 64),\n",
    "        (32, 32),\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "len_video = 1\n",
    "input_image_size = 512\n",
    "batch_size = 1\n",
    "shuffle = False\n",
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]\n",
    "transforms = [ComposeAPI([NormalizeAPI(mean=mean, std=std, v2=True)])]\n",
    "revert_mean=[-.485/.229, -.456/.224, -.406/.225]\n",
    "revert_std=[1/.229, 1/.224, 1/.225]\n",
    "revert_transform = Normalize(mean=revert_mean, std=revert_std)\n",
    "test_dataset = MiniDataset('over_train',\n",
    "                           len_video=len_video,\n",
    "                           input_image_size=input_image_size,\n",
    "                           object_labels=object_labels,\n",
    "                           transforms=transforms,\n",
    "                           collate_fn=collate_fn,\n",
    "                           batch_size=batch_size,\n",
    "                           shuffle=shuffle,\n",
    "                           get_seg_mask=True)\n",
    "print(f'Lenght of the dataset! {len(test_dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1  # Check seed 123 index 19966\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Image\n",
    "len_objects = len(object_labels)\n",
    "toPILimage = ToPILImage()\n",
    "exist = False\n",
    "if_break = False\n",
    "\n",
    "while True:\n",
    "    if if_break:\n",
    "        break\n",
    "    idx = np.random.randint(0, len(test_dataset))\n",
    "    # idx = 25424\n",
    "    print(f'Index: {idx}')\n",
    "    frame_obj_list, frames_segmentation_mask = test_dataset[idx]\n",
    "    for i in range(len_video):\n",
    "        image = frame_obj_list.frames[i].data\n",
    "        # Save the unnormalized image\n",
    "        print('Input Image:')\n",
    "        toPILimage(revert_transform(image)).show()\n",
    "        print('Segmentation Mask:')\n",
    "        # frames_segmentation_mask[i].show()\n",
    "        image = toPILimage(image)\n",
    "        print('Object Mask:')\n",
    "        for j in range(len_objects):\n",
    "            exist = torch.any(frame_obj_list.frames[i].objects[j].segment == True)\n",
    "            toPILimage(frame_obj_list.frames[i].objects[j].segment/255).show()\n",
    "            if_break = True if exist else if_break\n",
    "\n",
    "im_pred.set_image(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Point Copy-Paste from the sam2_tune\n",
    "O = len_objects\n",
    "points = torch.tensor([[i,i] for i in object_labels]).unsqueeze(1)\n",
    "labels = torch.tensor([[1]]).tile((O,1))\n",
    "print(f'Points: {points.data}')\n",
    "print(f'Labels: {labels.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Predict\n",
    "multimask_output = True\n",
    "masks, scores, logits = im_pred.predict(\n",
    "point_coords=points,\n",
    "point_labels=labels,\n",
    "multimask_output=multimask_output,\n",
    ")\n",
    "best_masks = deepcopy(masks)\n",
    "if multimask_output:\n",
    "    masks = masks[None,:,:,:] if len(masks.shape) == 3 else masks\n",
    "    scores = scores[None,:] if len(scores.shape) == 1 else scores\n",
    "    sorted_ind = np.argsort(scores, axis=1)[:,-1]\n",
    "    obj_ind = np.arange(len_objects)\n",
    "    best_masks = masks[obj_ind,sorted_ind]\n",
    "    best_scores = scores[obj_ind,sorted_ind]\n",
    "    # best_logits = logits[obj_ind,sorted_ind]\n",
    "for idx, mask in enumerate(best_masks):\n",
    "    toPILimage((mask*255).astype(np.uint8)).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trainenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
